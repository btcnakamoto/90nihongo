#!/usr/bin/env python3
"""
90å¤©æ—¥è¯­å­¦ä¹ å¹³å° - å¿«é€Ÿå¼€å§‹è„šæœ¬
æ¼”ç¤ºå¦‚ä½•å¿«é€Ÿè·å–NHK Easy Japaneseå†…å®¹å¹¶å¯¼å…¥
"""

import asyncio
import aiohttp
import feedparser
from pathlib import Path
import json
import re
from datetime import datetime
import sys

def print_banner():
    """æ‰“å°å¯åŠ¨æ¨ªå¹…"""
    print("ğŸŒ" * 20)
    print("90å¤©æ—¥è¯­å­¦ä¹ å¹³å° - å†…å®¹è·å–å·¥å…·")
    print("å¿«é€Ÿå¼€å§‹è„šæœ¬ v1.0")
    print("ğŸŒ" * 20)
    print()

def check_dependencies():
    """æ£€æŸ¥ä¾èµ–æ˜¯å¦å®‰è£…"""
    required_packages = ['aiohttp', 'feedparser']
    missing_packages = []
    
    for package in required_packages:
        try:
            __import__(package)
        except ImportError:
            missing_packages.append(package)
    
    if missing_packages:
        print("âŒ ç¼ºå°‘å¿…è¦çš„ä¾èµ–åŒ…:")
        for package in missing_packages:
            print(f"   - {package}")
        print("\nè¯·è¿è¡Œä»¥ä¸‹å‘½ä»¤å®‰è£…ä¾èµ–:")
        print("pip install aiohttp feedparser beautifulsoup4 requests aiofiles")
        return False
    
    print("âœ… æ‰€æœ‰ä¾èµ–å·²å®‰è£…")
    return True

async def get_nhk_articles(limit=5):
    """å¿«é€Ÿè·å–NHK Easyæ–‡ç« åˆ—è¡¨"""
    print(f"ğŸ“° æ­£åœ¨è·å–NHK Easyæ–‡ç«  (é™åˆ¶: {limit}ç¯‡)...")
    
    rss_url = "https://www3.nhk.or.jp/news/easy/rss/rss.xml"
    
    try:
        # è·å–RSS feed
        feed = feedparser.parse(rss_url)
        
        if not feed.entries:
            print("âŒ æ— æ³•è·å–NHK RSSå†…å®¹")
            return []
        
        articles = []
        for i, entry in enumerate(feed.entries[:limit]):
            article = {
                'title': entry.title,
                'url': entry.link,
                'published': entry.get('published', ''),
                'summary': entry.get('summary', '')[:100] + '...'
            }
            articles.append(article)
            print(f"   {i+1}. {article['title']}")
        
        print(f"âœ… æˆåŠŸè·å– {len(articles)} ç¯‡æ–‡ç« ")
        return articles
        
    except Exception as e:
        print(f"âŒ è·å–NHKæ–‡ç« å¤±è´¥: {e}")
        return []

async def simulate_content_download(articles):
    """æ¨¡æ‹Ÿä¸‹è½½å†…å®¹(å®é™…é¡¹ç›®ä¸­ä¼šçœŸå®ä¸‹è½½)"""
    print("\nğŸ”„ æ¨¡æ‹Ÿå†…å®¹ä¸‹è½½è¿‡ç¨‹...")
    
    downloaded_content = []
    
    for i, article in enumerate(articles, 1):
        print(f"   ä¸‹è½½ä¸­ [{i}/{len(articles)}]: {article['title'][:30]}...")
        
        # æ¨¡æ‹Ÿä¸‹è½½å»¶è¿Ÿ
        await asyncio.sleep(0.5)
        
        # æ¨¡æ‹Ÿç”Ÿæˆå†…å®¹
        content = {
            'id': i,
            'title': article['title'],
            'content': f"è¿™æ˜¯ç¬¬{i}ç¯‡æ–‡ç« çš„å†…å®¹æ‘˜è¦ã€‚" + article['summary'],
            'url': article['url'],
            'audio_available': True,  # æ¨¡æ‹ŸéŸ³é¢‘å¯ç”¨
            'difficulty': 'beginner' if i <= 2 else 'intermediate',
            'word_count': len(article['summary'].split()) * 10,  # ä¼°ç®—
            'download_time': datetime.now().isoformat()
        }
        downloaded_content.append(content)
    
    print("âœ… å†…å®¹ä¸‹è½½å®Œæˆ")
    return downloaded_content

def generate_csv_sample(content):
    """ç”ŸæˆCSVç¤ºä¾‹å†…å®¹"""
    print("\nğŸ“Š ç”ŸæˆCSVå¯¼å…¥æ–‡ä»¶...")
    
    # è¯¾ç¨‹CSVå†…å®¹
    courses_csv = "title,description,day_number,difficulty,tags,is_active,content\n"
    
    for item in content:
        # æ¸…ç†å†…å®¹ä¸­çš„é€—å·å’Œå¼•å·
        clean_title = item['title'].replace('"', '""').replace(',', 'ï¼Œ')
        clean_content = item['content'].replace('"', '""').replace(',', 'ï¼Œ')
        
        courses_csv += f'"{clean_title}","ç¬¬{item["id"]}å¤©è¯¾ç¨‹å†…å®¹",{item["id"]},"{item["difficulty"]}","[""æ—¥è¯­å­¦ä¹ "",""NHKæ–°é—»""]",true,"{clean_content}"\n'
    
    # ä¿å­˜æ–‡ä»¶
    output_dir = Path("sample_import")
    output_dir.mkdir(exist_ok=True)
    
    courses_file = output_dir / "courses.csv"
    with open(courses_file, 'w', encoding='utf-8') as f:
        f.write(courses_csv)
    
    print(f"âœ… CSVæ–‡ä»¶å·²ç”Ÿæˆ: {courses_file}")
    return courses_file

def generate_report(content, csv_file):
    """ç”ŸæˆæŠ¥å‘Š"""
    print("\nğŸ“‹ ç”Ÿæˆè·å–æŠ¥å‘Š...")
    
    report = {
        'timestamp': datetime.now().isoformat(),
        'source': 'NHK Easy Japanese',
        'total_articles': len(content),
        'csv_file': str(csv_file),
        'articles': content,
        'next_steps': [
            "1. ä½¿ç”¨ç½‘ç«™çš„æ‰¹é‡å¯¼å…¥åŠŸèƒ½ä¸Šä¼  " + str(csv_file),
            "2. åœ¨éŸ³é¢‘ç®¡ç†ä¸­ä¸Šä¼ å¯¹åº”çš„éŸ³é¢‘æ–‡ä»¶",
            "3. ä½¿ç”¨æ™ºèƒ½å…³è”åŠŸèƒ½å…³è”éŸ³é¢‘ä¸å†…å®¹",
            "4. æµ‹è¯•å­¦ä¹ æ•ˆæœå¹¶è°ƒæ•´å†…å®¹"
        ]
    }
    
    report_file = Path("sample_import") / "report.json"
    with open(report_file, 'w', encoding='utf-8') as f:
        json.dump(report, f, ensure_ascii=False, indent=2)
    
    print(f"âœ… æŠ¥å‘Šå·²ç”Ÿæˆ: {report_file}")
    return report

def print_summary(report):
    """æ‰“å°æ€»ç»“"""
    print("\n" + "ğŸ‰" * 20)
    print("è·å–å®Œæˆ! æ€»ç»“å¦‚ä¸‹:")
    print("ğŸ‰" * 20)
    print(f"ğŸ“Š è·å–æ–‡ç« æ•°: {report['total_articles']}")
    print(f"ğŸ“ CSVæ–‡ä»¶: {report['csv_file']}")
    print(f"â° å¤„ç†æ—¶é—´: {report['timestamp']}")
    print("\nğŸ“‹ ä¸‹ä¸€æ­¥æ“ä½œ:")
    for i, step in enumerate(report['next_steps'], 1):
        print(f"   {i}. {step}")
    
    print("\nğŸ’¡ æç¤º:")
    print("   - è¿™æ˜¯æ¼”ç¤ºç‰ˆæœ¬ï¼Œå®é™…ç‰ˆæœ¬ä¼šä¸‹è½½å®Œæ•´çš„æ–‡æœ¬å’ŒéŸ³é¢‘")
    print("   - å¯ä»¥åœ¨ç½‘ç«™ç®¡ç†åå°ä½¿ç”¨æ‰¹é‡å¯¼å…¥åŠŸèƒ½å¯¼å…¥CSVæ–‡ä»¶")
    print("   - å»ºè®®å…ˆå°è§„æ¨¡æµ‹è¯•ï¼Œç¡®è®¤æ•ˆæœåå†å¤§è§„æ¨¡å¯¼å…¥")

async def main():
    """ä¸»å‡½æ•°"""
    print_banner()
    
    # æ£€æŸ¥ä¾èµ–
    if not check_dependencies():
        return 1
    
    try:
        # è·å–æ–‡ç« åˆ—è¡¨
        articles = await get_nhk_articles(limit=5)
        if not articles:
            print("âŒ æ— æ³•è·å–æ–‡ç« ï¼Œè¯·æ£€æŸ¥ç½‘ç»œè¿æ¥")
            return 1
        
        # æ¨¡æ‹Ÿä¸‹è½½å†…å®¹
        content = await simulate_content_download(articles)
        
        # ç”ŸæˆCSVæ–‡ä»¶
        csv_file = generate_csv_sample(content)
        
        # ç”ŸæˆæŠ¥å‘Š
        report = generate_report(content, csv_file)
        
        # æ‰“å°æ€»ç»“
        print_summary(report)
        
        print("\nğŸš€ å¿«é€Ÿå¼€å§‹æ¼”ç¤ºå®Œæˆ!")
        print("   ç°åœ¨æ‚¨å¯ä»¥ä½¿ç”¨å®Œæ•´ç‰ˆçš„çˆ¬è™«å·¥å…·è·å–æ›´å¤šå†…å®¹")
        
        return 0
        
    except KeyboardInterrupt:
        print("\n\nâ¸ï¸  ç”¨æˆ·ä¸­æ–­æ“ä½œ")
        return 1
    except Exception as e:
        print(f"\nâŒ å‘ç”Ÿé”™è¯¯: {e}")
        return 1

if __name__ == "__main__":
    if sys.platform.startswith('win'):
        # Windowsä¸‹è®¾ç½®äº‹ä»¶å¾ªç¯ç­–ç•¥
        asyncio.set_event_loop_policy(asyncio.WindowsProactorEventLoopPolicy())
    
    try:
        result = asyncio.run(main())
        sys.exit(result)
    except Exception as e:
        print(f"ç¨‹åºæ‰§è¡Œå¤±è´¥: {e}")
        sys.exit(1) 